
启动nginx




bin/kafka-topics.sh --zookeeper hadoop200:2182 --create --replication-factor 2 --partitions 3 --topic log_analysis

开启flume
bin/flume-ng agent --conf conf/ --name a1 --conf-file agent/log1.conf -Dlog1 & > log1.log
bin/flume-ng agent --conf conf/ --name a1 --conf-file agent/log2.conf -Dlog2 & > log2.log

/opt/module/kafka_2.11-0.8.2.1/bin/kafka-console-consumer.sh --zookeeper hadoop202:2182 --from-beginning --topic log_analysis

双层结构
日志采集sink 至 汇总flume
bin/flume-ng agent --conf conf/ --name a1 --conf-file agent/log21.conf -Dlog21 & > log21.log
bin/flume-ng agent --conf conf/ --name a1 --conf-file agent/log22.conf -Dlog22 & > log22.log
日志汇总至kafka
bin/flume-ng agent --conf conf/ --name a1 --conf-file agent/log23.conf -Dlog23 & > log23.log


hive:
1.添加json支持 hive-site.xml
  <property>
    <name>hive.aux.jars.path</name>
    <value>file:///opt/module/apache-hive-1.2.2-bin/lib/json-serde-1.3.8-jar-with-dependencies.jar</value>
    <description>The location of the plugin jars that contain implementations of user defined functions and serdes.</description>
  </property>
创建数据库：
hive (default)> show databases;
创建applogsdb：
hive (default)> create database applogsdb;

hive (default)> use applogsdb;

hive (applogsdb)> CREATE external TABLE ext_startup_logs(userId string,appPlatform string,appId
string,startTimeInMs bigint,activeTimeInMs bigint,appVersion string,city
string)PARTITIONED BY (ym string, day string,hm string) ROW FORMAT SERDE
'org.openx.data.jsonserde.JsonSerDe' STORED AS TEXTFILE;

SERDE:SerDe是Serialize/Deserilize的简称，目的是用于序列化和反序列化。

创建hive脚本：

#!/bin/bash
# 获取三分钟之前的时间
systime=`date -d "-3 minute" +%Y%m-%d-%H%M`
# 获取年月
ym=`echo ${systime} | awk -F '-' '{print $1}'`
# 获取日
day=`echo ${systime} | awk -F '-' '{print $2}'`
# 获取小时分钟
hm=`echo ${systime} | awk -F '-' '{print $3}'`
# 执行 hive 命令
/opt/module/apache-hive-1.2.2-bin/bin/hive -e "load data inpath '/user/soap/applogs/startup/${ym}/${day}/${hm}' into table
applogsdb.ext_startup_logs partition(ym='${ym}',day='${day}',hm='${hm}')"

配置 crontab -e
* * * * *  /opt/app/job/load2hive.sh

配置UDF 函数支持 hive-site.xml

 <property>
    <name>hive.aux.jars.path</name>
    <value>file:///opt/module/apache-hive-1.2.2-bin/lib/json-serde-1.3.8-jar-with-dependencies.jar,file:///opt/module/apache-hive-1.2.2-bin/lib/common.jar.jar</value>
    <description>The location of the plugin jars that contain implementations of user defined functions and serdes.</description>
  </property>

 注册永久函数(注册需指定哪个库)
hive (default)> use applogsdb;

hive (default)> create function getdaybegin AS 'com.soap.hive.DayBeginUDF';
hive (default)> create function getweekbegin AS 'com.soap.hive.WeekBeginUDF';
hive (default)> create function getmonthbegin AS 'com.soap.hive.MonthBeginUDF';
hive (default)> create function formattime AS 'com.soap.hive.FormatTimeUDF';

验证注册：
select * from metastore.FUNCS;


删除函数：
hive (default)>  drop function getdaybegin;

1、新增用户

1) 今日新增用户：

select
count(*)
from
(select min(startTimeInMs) mintime
from ext_startup_logs
where appId = 'app00001'
group by userId
having mintime >= getdaybegin() and mintime < getdaybegin(1)
)t ;

2) 昨天新增用户：
select
count(*)
from
(select min(startTimeInMs) mintime
from ext_startup_logs
where appId = 'app00001'
group by userId
having mintime >= getdaybegin(-1) and mintime < getdaybegin()
)t ;

3) 指定天新增用户：
select
count(*)
from
(select min(startTimeInMs) mintime
from ext_startup_logs
where appId = 'app00001'
group by userId
having mintime >= getdaybegin('2018/04/27 18:22:11') and mintime < getdaybegin('2018/04/27 18:22:11',1)
)t ;

2、任意周新增

1)本周新增
select
count(*)
from
(select min(startTimeInMs) mintime
from ext_startup_logs
where appId = 'app00001'
group by userId
having mintime >= getweekbegin() and mintime < getweekbegin(1)
)t ;

3、月新增
select
count(*)
from
(select min(startTimeInMs) mintime
from ext_startup_logs
where appId = 'app00001'
group by userId
having mintime >= getmonthbegin() and mintime < getmonthbegin(1)
)t ;

4、日活跃用户

select
count(distinct userId)
from ext_startup_logs
where appId = 'app0001'
and startTimeInMs >= getdaybegin() and startTimeInMs < getdaybegin(1);

5.日活、周活、月活
一次查询一周每天的活跃用户

1) 一周每一天的日活
select
formattime(startTimeInMs,'yyyy/MM/dd') day ,count(distinct userId)
from ext_startup_logs
where appId = 'app0001'
and startTimeInMs >= getweekbegin() and startTimeInMs < getweekbegin(1)
group by formattime(startTimeInMs,'yyyy/MM/dd');

2) 五周内每一周的周活:将每一周的日期格式化为每周第一天
select
formattime(startTimeInMs,'yyyy/MM/dd',0) week,count(distinct userId)
from ext_startup_logs
where appId = 'app0001'
and startTimeInMs >= getweekbegin(-5) and startTimeInMs < getweekbegin()
group by formattime(startTimeInMs,'yyyy/MM/dd',0);

3) 一次查询出过去的三个月内，每周的月活跃数:将每月的日期个数化为每月第一天

select
formattime(startTimeInMs,'yyyy/MM',0) day ,count(distinct userId)
from ext_startup_logs
where appId = 'app0001'
and startTimeInMs >= getmonthbegin(-3) and startTimeInMs < getmonthbegin()
group by formattime(startTimeInMs,'yyyy/MM',0);